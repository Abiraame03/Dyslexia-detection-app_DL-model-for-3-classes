# -*- coding: utf-8 -*-
"""appDL3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dlNBGwXkXR6LvCa4Zf21VmvN460LI03T
"""

import streamlit as st
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from PIL import Image
import pickle
from gtts import gTTS
import base64
import os

MODEL_PATH = "best_model.keras"
CLASS_INDEX_PATH = "class_indices.pkl"

# -----------------------------
# Load Model + Class Mapping
# -----------------------------
@st.cache_resource
def load_my_model():
    return load_model(MODEL_PATH)

@st.cache_resource
def load_class_map():
    with open(CLASS_INDEX_PATH, "rb") as f:
        mapping = pickle.load(f)
    return {v: k for k, v in mapping.items()}  # invert

model = load_my_model()
inv_map = load_class_map()

IMG_SIZE = (160, 160)

# -----------------------------
# Preprocessing
# -----------------------------
def preprocess(img):
    img = img.resize(IMG_SIZE)
    img = np.array(img) / 255.0
    return np.expand_dims(img, axis=0)

# -----------------------------
# Severity Logic
# -----------------------------
def get_severity(score):
    if score < 0.40:
        return "Normal"
    elif score < 0.55:
        return "Mild Dyslexic Features"
    elif score < 0.75:
        return "Moderate Dyslexic Features"
    else:
        return "Severe Dyslexic Features"

# -----------------------------
# Text ‚Üí Audio (Auto-Play)
# -----------------------------
def text_to_audio(text):
    tts = gTTS(text=text, lang='en')
    path = "voice.mp3"
    tts.save(path)
    audio_file = open(path, "rb").read()
    b64 = base64.b64encode(audio_file).decode()
    os.remove(path)
    return f"""
    <audio autoplay>
        <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
    </audio>
    """

# -----------------------------
# Predict Function
# -----------------------------
def predict(img):
    processed = preprocess(img)
    pred = model.predict(processed)[0]

    # find dyslexia index
    dys_idx = None
    for k, v in inv_map.items():
        if v.lower() in ["dyslexia", "dyslexic"]:
            dys_idx = k
    if dys_idx is None:
        dys_idx = 1  # default

    score = pred[dys_idx]
    severity = get_severity(score)
    return score, severity

# -----------------------------
# Streamlit UI
# -----------------------------
st.set_page_config(page_title="Dyslexia Screening System", layout="wide")
st.title("üß† AI-Based Dyslexia Screening Tool")
st.write("Upload handwriting or capture using camera to analyze dyslexic patterns.")

# -----------------------------
# Camera Input
# -----------------------------
st.subheader("üì∏ Capture Using Camera")
camera_photo = st.camera_input("Take handwriting photo")

if camera_photo:
    img = Image.open(camera_photo).convert("RGB")
    st.image(img, caption="Captured Image", width=350)

    score, severity = predict(img)

    st.success(f"üîç **Severity: {severity}**")
    st.info(f"Dyslexia Probability: {score * 100:.2f}%")

    st.markdown(text_to_audio(f"This handwriting shows {severity}"), unsafe_allow_html=True)

# -----------------------------
# Upload Input
# -----------------------------
st.subheader("üì§ Upload Handwriting Image")
upload = st.file_uploader("Upload image...", type=["jpg", "jpeg", "png"])

if upload:
    img = Image.open(upload).convert("RGB")
    st.image(img, caption="Uploaded Image", width=350)

    score, severity = predict(img)

    st.success(f"üîç **Severity: {severity}**")
    st.info(f"Dyslexia Probability: {score * 100:.2f}%")

    st.markdown(text_to_audio(f"This handwriting shows {severity}"), unsafe_allow_html=True)
